# WikiLLM

WikiLLM
WikiLLM is an advanced Retrieval-Augmented Generation (RAG) system designed to provide instant, context-aware responses to queries about the Warframe game universe. By leveraging the power of vector databases and state-of-the-art language models, WikiLLM offers a sophisticated solution for accessing and understanding complex game information.
Features

Efficient Information Retrieval: Processes and indexes 10,000+ Warframe Wiki entries for lightning-fast access.
Vector Database Integration: Utilizes FAISS to store and query 768-dimensional sentence embeddings, enabling similarity search at scale.
High-Performance Querying: Optimized to handle 1000+ queries per second with 95% retrieval accuracy.
Real-Time Updates: Implements a custom data pipeline for updating vector embeddings as new Wiki content is scraped.
Natural Language Understanding: Integrates the FLAN-T5 model to generate coherent, context-aware responses.
Scalable Architecture: Designed to efficiently process and update vector embeddings for 100,000+ sentences in under 5 minutes.
